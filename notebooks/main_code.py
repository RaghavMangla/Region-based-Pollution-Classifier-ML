# -*- coding: utf-8 -*-
"""main_code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ol_8W9O9BQAB4cwC4DheHy4njJM4bRpE
"""

# Importing libraries
from __future__ import print_function
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report
from sklearn import metrics
from sklearn import tree

import warnings
from sklearn.metrics import precision_recall_curve, roc_curve
from sklearn.preprocessing import label_binarize
warnings.filterwarnings('ignore')

df = pd.read_csv('../datasets/PollutionDataset.csv')
df=np.array(df)
df=df[:12000]
# plt.scatter(df['pm2_5'], df['Label'])
# plt.xlabel('PM 2.5 conc.(in micrograms/m3)')
# plt.ylabel('Class')
# plt.title('PM 2.5 relation with class labels')
# plt.legend()
# plt.show()


# plt.scatter(df['Leq'], df['Label'])
# plt.xlabel('Leq(in dB)')
# plt.ylabel('Class')
# plt.title('Leq relation with class labels')
# plt.legend()
# plt.show()

# df.head()

# df.columns

# ax = sns.heatmap(df.corr(),annot=True,fmt='0.2f',cmap='Blues')
# ax

features = df[:,[0,1,2,3,4,5,6,7,9,10]]
target = df[:,11].astype(int)
labels = df[:,11].astype(int)
acc = []
model = []
from sklearn.model_selection import train_test_split
Xtrain, Xtest, Ytrain, Ytest = train_test_split(features,target,test_size = 0.2,random_state =2)

features

"""Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import roc_curve, auc

DecisionTree = DecisionTreeClassifier(criterion="entropy",random_state=2,max_depth=5)

DecisionTree.fit(Xtrain,Ytrain)

predicted_values = DecisionTree.predict(Xtest)
x = metrics.accuracy_score(Ytest, predicted_values)
acc.append(x)
model.append('Decision Tree')
print("DecisionTrees's Accuracy is: ", x*100)
print()
print("Confusion Matrix: ")
print(metrics.confusion_matrix(Ytest,predicted_values))
print()
ax=classification_report(Ytest,predicted_values)
print(ax)



from sklearn.model_selection import cross_val_score

# Cross validation score (Decision Tree)
score = cross_val_score(DecisionTree, features, target,cv=5)

score

"""Saving trained Decision Tree Model"""

import pickle
# Dump the trained Naive Bayes classifier with Pickle
DT_pkl_filename = '../models/DecisionTree.pkl'
# Open the file to save as pkl file
DT_Model_pkl = open(DT_pkl_filename, 'wb')
pickle.dump(DecisionTree, DT_Model_pkl)
# Close the pickle instances
DT_Model_pkl.close()

"""Guassian Naive Bayes"""

from sklearn.naive_bayes import GaussianNB

NaiveBayes = GaussianNB()

NaiveBayes.fit(Xtrain,Ytrain)

predicted_values = NaiveBayes.predict(Xtest)
x = metrics.accuracy_score(Ytest, predicted_values)
acc.append(x)
model.append('Naive Bayes')
print("Naive Bayes's Accuracy is: ", x)

print()
print("Confusion Matrix: ")
print(metrics.confusion_matrix(Ytest,predicted_values))
print()
ax=classification_report(Ytest,predicted_values)
print(ax)

# Cross validation score (NaiveBayes)
score = cross_val_score(NaiveBayes,features,target,cv=5)

score

"""Saving trained Guassian Naive Bayes model"""

import pickle
# Dump the trained Naive Bayes classifier with Pickle
NB_pkl_filename = '../models/NBClassifier.pkl'
# Open the file to save as pkl file
NB_Model_pkl = open(NB_pkl_filename, 'wb')
pickle.dump(NaiveBayes, NB_Model_pkl)
# Close the pickle instances
NB_Model_pkl.close()

"""Support Vector Machine (SVM)"""

from sklearn.svm import SVC
# data normalization with sklearn
from sklearn.preprocessing import MinMaxScaler
# fit scaler on training data
norm = MinMaxScaler().fit(Xtrain)
X_train_norm = norm.transform(Xtrain)
# transform testing dataabs
X_test_norm = norm.transform(Xtest)
SVM = SVC(kernel='poly', degree=3, C=1)
SVM.fit(X_train_norm,Ytrain)
predicted_values = SVM.predict(X_test_norm)
x = metrics.accuracy_score(Ytest, predicted_values)
acc.append(x)
model.append('SVM')
print("SVM's Accuracy is: ", x)

print()
print("Confusion Matrix: ")
print(metrics.confusion_matrix(Ytest,predicted_values))
print()
ax=classification_report(Ytest,predicted_values)
print(ax)

# Cross validation score (SVM)
score = cross_val_score(SVM,features,target,cv=5)
score

"""Saving trained SVM model"""

import pickle
# Dump the trained SVM classifier with Pickle
SVM_pkl_filename = '../models/SVMClassifier.pkl'
# Open the file to save as pkl file
SVM_Model_pkl = open(SVM_pkl_filename, 'wb')
pickle.dump(SVM, SVM_Model_pkl)
# Close the pickle instances
SVM_Model_pkl.close()

"""Logistic Regression"""

from sklearn.linear_model import LogisticRegression

LogReg = LogisticRegression(random_state=2)

LogReg.fit(Xtrain,Ytrain)

predicted_values = LogReg.predict(Xtest)

x = metrics.accuracy_score(Ytest, predicted_values)
acc.append(x)
model.append('Logistic Regression')
print("Logistic Regression's Accuracy is: ", x)

print()
print("Confusion Matrix: ")
print(metrics.confusion_matrix(Ytest,predicted_values))
print()
ax=classification_report(Ytest,predicted_values)
print(ax)

# Cross validation score (Logistic Regression)
score = cross_val_score(LogReg,features,target,cv=5)

score

"""saving trained Logistic Regression Model"""

import pickle
# Dump the trained Naive Bayes classifier with Pickle
LR_pkl_filename = '../models/LogisticRegression.pkl'
# Open the file to save as pkl file
LR_Model_pkl = open(LR_pkl_filename, 'wb')
pickle.dump(LogReg, LR_Model_pkl)
# Close the pickle instances
LR_Model_pkl.close()

"""ANN"""

import tensorflow as tf
import keras
from tensorflow import keras
from keras import layers
from keras.utils import to_categorical

# Define the model
ann = keras.Sequential([
    layers.Dense(1024, activation='sigmoid', input_shape=(10,)),
    layers.Dense(512, activation='sigmoid'),
    layers.Dense(256, activation='sigmoid'),
    layers.Dense(128, activation='sigmoid'),
     layers.Dense(64, activation='sigmoid'),
    layers.Dense(32, activation='sigmoid'),
    layers.Dense(16, activation='softmax')
])

# Compile the model
ann.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
y_train_hot = to_categorical(Ytrain,16) #to cnvrt to one_hot_encoding format
ann.fit(Xtrain, y_train_hot, epochs=10)

# Make predictions
predicted_values=ann.predict(Xtest).argmax(axis=1)

x = metrics.accuracy_score(Ytest, predicted_values)
acc.append(x)
model.append('ANN')
print("ANN's Accuracy is: ", x)

print()
print("Confusion Matrix: ")
print(metrics.confusion_matrix(Ytest,predicted_values))
print()
ax=classification_report(Ytest,predicted_values)
print(ax)

import pickle
# Dump the trained ANN classifier with Pickle
ANN_pkl_filename = '../models/ANN.pkl'
# Open the file to save as pkl file
ANN_Model_pkl = open(ANN_pkl_filename, 'wb')
pickle.dump(ann, ANN_Model_pkl)
# Close the pickle instances
ANN_Model_pkl.close()

"""Random Forest"""

from sklearn.ensemble import RandomForestClassifier

RF = RandomForestClassifier(n_estimators=20, random_state=0)
RF.fit(Xtrain,Ytrain)

predicted_values = RF.predict(Xtest)

x = metrics.accuracy_score(Ytest, predicted_values)
acc.append(x)
model.append('RF')
print("RF's Accuracy is: ", x)

print()
print("Confusion Matrix: ")
print(metrics.confusion_matrix(Ytest,predicted_values))
print()
ax=classification_report(Ytest,predicted_values)
print(ax)

# Cross validation score (Random Forest)
score = cross_val_score(RF,features,target,cv=5)
score

"""saving trained Random Forest model"""

import pickle
# Dump the trained Random Forest classifier with Pickle
RF_pkl_filename = '../models/RandomForest.pkl'
# Open the file to save as pkl file
RF_Model_pkl = open(RF_pkl_filename, 'wb')
pickle.dump(RF, RF_Model_pkl)
# Close the pickle instances
RF_Model_pkl.close()

"""XGBoost"""

import xgboost as xgb
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
Ytrain = le.fit_transform(Ytrain)
XB = xgb.XGBClassifier()
XB.fit(Xtrain,Ytrain)

predicted_values = XB.predict(Xtest)
predicted_values = le.inverse_transform(predicted_values)

x = metrics.accuracy_score(Ytest, predicted_values)
acc.append(x)
model.append('XGBoost')
print("XGBoost's Accuracy is: ", x)

print()
print("Confusion Matrix: ")
print(metrics.confusion_matrix(Ytest,predicted_values))
print()
ax=classification_report(Ytest,predicted_values)
print(ax)

# Cross validation score (XGBoost)
score = cross_val_score(XB,features,target,cv=5)

score

"""saving trained XGBoost Model"""

import pickle
# Dump the trained Naive Bayes classifier with Pickle
XB_pkl_filename = '../models/XGBoost.pkl'
# Open the file to save as pkl file
XB_Model_pkl = open(XB_pkl_filename, 'wb')
pickle.dump(XB, XB_Model_pkl)
# Close the pickle instances
XB_Model_pkl.close()

"""Accuracy Comparison"""

plt.figure(figsize=[10,5],dpi = 100)
plt.title('Accuracy Comparison')
plt.xlabel('Accuracy')
plt.ylabel('Algorithm')
sns.barplot(x = acc,y = model,palette='dark')

accuracy_models = dict(zip(model, acc))
for k, v in accuracy_models.items():
    print (k, '-->', v)

"""Making a prediction"""

#prediction for Delhi, ideal answer is industrial,soil,marine and urban pollution
data = np.array([[87.74, 44.82 ,136.98,241.37,70.19,6.8,7.8,16,1.5,0.55]])
prediction = RF.predict(data)
print(prediction)

#prediction for Andaman and Nicobar Islands, ideal answer is marine pollution
data = np.array([[0.13,0.05,4.77,5.23,60.2,7,7.2,3,5.1,0.75]])
prediction = XB.predict(data)
prediction=le.inverse_transform(prediction)
print(prediction)

#prediction for Punjab
data = np.array([[33.93,5.07,88.58,112.23,69.1,5,7.3,19.3,86.3,0.61]])
prediction = DecisionTree.predict(data)
print(prediction)

