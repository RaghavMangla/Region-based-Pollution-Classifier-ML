# -*- coding: utf-8 -*-
"""Important.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y2KlIEKvq5MO1kcyjGMe4vKvFA7AKrUV
"""

import requests
from pprint import pprint
import pandas as pd
from google.colab import files

key='5b089e610a83eb82a7f7b4bb610407b1'


df = pd.DataFrame(columns=['co', 'no', 'no2', 'o3', 'so2', 'pm2_5', 'pm10', 'nh3', 'aqi'])

l=[[43.2965, 5.3698],
[41.6501, -70.4812],
[1.6744, 31.7150],
[2.3363, 102.2323],
[13.0000, 15.7333],
[-10.6833, 35.8667],
[36.7342, 9.0955],
[49.2358, 12.0731],
[10.7400, 122.5636],
[20.1428, -77.1586],
[15.1107, -16.6251],
[4.2146, -74.4937],
[-34.6500, -59.4300],
[39.0236, -94.6936],
[45.1806, -89.6830],
[47.8278, 20.5719],
[51.7542, 4.1681],
[37.4229, 41.3430],
[-4.1650, -42.8967],
[-34.3780, -55.2400],
[-9.5297, -48.5925],
[27.1333, 80.2833],
[30.8204, 75.1700],
[45.5543, 12.2368],
[-7.4697, 112.4711],
[44.3528, 143.3564],
[14.7403, 121.1166],
[44.0176, 1.3546],
[48.7705, 2.0190],
[47.4233, 18.9656],
[22.0873, 90.7416],
[ 51.1717, 4.4598],
[46.7324, -117.0002],
[16.3333, 75.2833],
[45.6512, 9.2265],
[50.4289, 7.5683],
[20.4667, 89.7167],
[ 50.2136, 19.1569]]

for i in range(len(l)):
  lat=str(l[i][0])
  lon=str(l[i][1])
  url='http://api.openweathermap.org/data/2.5/air_pollution?lat='+lat+'&lon='+lon+'&appid='+key+'&units=metric'
  response=requests.get(url).json()

  # Extract information from the API response
  co = response['list'][0]['components']['co']
  no = response['list'][0]['components']['no']
  no2 = response['list'][0]['components']['no2']
  o3 = response['list'][0]['components']['o3']
  so2 = response['list'][0]['components']['so2']
  pm2_5 = response['list'][0]['components']['pm2_5']
  pm10 = response['list'][0]['components']['pm10']
  nh3 = response['list'][0]['components']['nh3']
  aqi = response['list'][0]['main']['aqi']

# Append the extracted information to the DataFrame
  df = df._append({
    'co': co,
    'no': no,
    'no2': no2,
    'o3': o3,
    'so2': so2,
    'pm2_5': pm2_5,
    'pm10': pm10,
    'nh3': nh3,
    'aqi': aqi
  }, ignore_index=True)



df.to_csv('info.csv', index=False)

# Download the CSV file to your local machine
files.download('info.csv')

import requests
from pprint import pprint
import pandas as pd
from google.colab import files
import numpy as np




df = pd.DataFrame(columns=['no2','so2', 'pm2_5', 'pm10','Leq','DO','pH','BOD','wqi','Land_use','NBR','Label'])


for i in range(24000):
  # Extract information from the API response
  no2 = abs(np.random.rand())*100.0
  so2 = abs(np.random.rand())*100.0
  pm2_5 = abs(np.random.rand())*100.0
  pm10 = abs(np.random.rand())*200.0
  leq=abs(np.random.rand())*100.0
  d_o=abs(np.random.rand())*(10.0)
  ph=abs(np.random.rand())*(8.0) + 2.0
  bod=abs(np.random.rand())*(130.0)
  lu=(abs(np.random.rand()))*(100)
  nbr=(abs(np.random.rand())*(1.0))
  label=int(0)

  if pm2_5>15.0 or so2>=40.0:
    label=label+1

  if leq>=60 and (pm10>=45 or no2>=25):
    label=label+2

  if lu>=40 and nbr<0.8:
    label=label+8

  nph=0

  if (8.5>=ph>=7):
    nph=100
  elif  (8.6>=ph>=8.5) or (6.9>=ph>=6.8):
    nph=80
  elif (8.8>=ph>=8.6) or (6.8>=ph>=6.7):
    nph=60
  elif (9>=ph>=8.8) or (6.7>=ph>=6.5):
    nph=40

  ndo=0

  if (d_o>=6):
    ndo=100
  elif (6>=d_o>=5.1):
    ndo=80
  elif (5>=d_o>=4.1):
    ndo=60
  elif (4>=d_o>=3):
    ndo=40

  nbod=0

  if (3>=bod>=0):
    nbod=100
  elif  (6>=bod>=3):
    nbod=80
  elif (80>=bod>=6):
    nbod=60
  elif (125>=bod>=80):
    nbod=40

  x=nph * 0.2
  y=ndo * 0.3
  z=nbod * 0.5
  wqi=x+y+z

  if nbod<=60 or ndo<=60:
    label=label+4


# Append the extracted information to the DataFrame
  df = df._append({
    'no2': no2,
    'so2': so2,
    'pm2_5': pm2_5,
    'pm10': pm10,
    'Leq':leq,
    'DO':d_o,
    'pH':ph,
    'BOD':bod,
    'wqi':wqi,
    'Land_use':lu,
    'NBR':nbr,
    'Label':int(label)
  }, ignore_index=True)



df.to_csv('data.csv', index=False)

# Download the CSV file to your local machine
files.download('data.csv')

import pandas as pd
from google.colab import files

# Assuming 'water_quality.csv' is your CSV file
csv_file = 'water_dataX.csv'

# Read the CSV file into a pandas DataFrame
df = pd.read_csv(csv_file)

# Filter rows where the length of the 'state' column does not exceed 15
df_filtered = df[df['STATE'].apply(lambda x: len(str(x)) <= 15)]

# Specify the columns for which you want to calculate averages
columns_to_average = ['BOD', 'DO', 'pH','NN+N']

# Group by 'state' and calculate the average for each specified column
df_avg = df_filtered[columns_to_average].mean().groupby('STATE').resetindex()

# Save the result to a new CSV file
output_csv = 'average_water_quality.csv'
df_avg.to_csv(output_csv, index=False)

files.download(output_csv)